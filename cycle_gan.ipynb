{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os2jA2HZB3us"
      },
      "source": [
        "# CycleGAN TensorFlow Implementation\n",
        "\n",
        "Created by Paul Scott<br><br>\n",
        "References:\n",
        "* https://www.tensorflow.org/tutorials/generative/cyclegan\n",
        "* https://machinelearningmastery.com/cyclegan-tutorial-with-keras/\n",
        "* https://www.tensorflow.org/tutorials/generative/pix2pix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq8uC10mUVc3"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djwCPihmhSGE"
      },
      "source": [
        "### Install Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i27_v2ETmaIG"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%pip install tensorflow_addons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqqBb6vbEXVX"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ecjc9slbAOcN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import models, layers, losses, optimizers\n",
        "import tensorflow_addons.layers as tfa_layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import time\n",
        "import shutil\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbOGCDhTEUiP"
      },
      "source": [
        "### Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsTJ6L-czvky"
      },
      "outputs": [],
      "source": [
        "def preprocess(x):\n",
        "  return (x - 127.5) / 127.5\n",
        "\n",
        "\n",
        "def postprocess(x):\n",
        "  return x * 0.5 + 0.5\n",
        "\n",
        "\n",
        "def make_dir(directory):\n",
        "  if not os.path.isdir(directory):\n",
        "    os.makedirs(directory)\n",
        "\n",
        "\n",
        "def remove_dir(directory):\n",
        "  if os.path.isdir(directory):\n",
        "    shutil.rmtree(directory)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-aWQQflU15T"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jv4tTxBVks5b"
      },
      "source": [
        "### Choose Dataset And Define Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjlpEOU7WBA0"
      },
      "outputs": [],
      "source": [
        "dataset_name = 'vangogh2photo'\n",
        "class_x, class_y = dataset_name.split('2')\n",
        "\n",
        "env_dir = 'drive/MyDrive/colab_envs/cycle_gan_env'\n",
        "checkpoint_dir = f'{env_dir}/checkpoints/{dataset_name}'\n",
        "output_images_dir = f'{env_dir}/output_images/{dataset_name}'\n",
        "sample_images_dir = f'{env_dir}/sample_images'\n",
        "model_diagrams_dir = f'{env_dir}/model_diagrams'\n",
        "generators_dir = f'{env_dir}/generators'\n",
        "metrics_dir = f'{env_dir}/metrics'\n",
        "\n",
        "make_dir(env_dir)\n",
        "make_dir(checkpoint_dir)\n",
        "make_dir(output_images_dir)\n",
        "make_dir(sample_images_dir)\n",
        "make_dir(model_diagrams_dir)\n",
        "make_dir(generators_dir)\n",
        "make_dir(metrics_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZD9SoDZkwtc"
      },
      "source": [
        "### Get Dataset From Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJ2E83iuhyMD"
      },
      "outputs": [],
      "source": [
        "!unzip -q drive/MyDrive/datasets/{dataset_name}.zip -d ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEv0OMi4k111"
      },
      "source": [
        "### Create Dataset Iterators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzzQOGnxUkw0"
      },
      "outputs": [],
      "source": [
        "img_dim = 256\n",
        "img_shape = (img_dim, img_dim, 3)\n",
        "\n",
        "assert img_dim >= 32\n",
        "assert np.log2(img_dim) == int(np.log2(img_dim))\n",
        "\n",
        "def random_jitter(image):\n",
        "  jitter_amount = img_dim // 8\n",
        "  jitter_dim = img_dim + jitter_amount\n",
        "  image = tf.image.resize(image, (jitter_dim, jitter_dim), method=tf.image.ResizeMethod.AREA)\n",
        "  image = tf.image.random_crop(image, size=img_shape)\n",
        "  image = tf.image.random_flip_left_right(image)\n",
        "  image = tf.clip_by_value(image, 0, 255)\n",
        "  image = preprocess(image)\n",
        "  return image\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=random_jitter)\n",
        "\n",
        "train_x = datagen.flow_from_directory(\n",
        "    f'{dataset_name}/train_x',\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    interpolation='box',\n",
        ")\n",
        "\n",
        "train_y = datagen.flow_from_directory(\n",
        "    f'{dataset_name}/train_y',\n",
        "    target_size=(img_dim, img_dim),\n",
        "    batch_size=1,\n",
        "    class_mode=None,\n",
        "    interpolation='box',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WhUi7PqblI-1"
      },
      "source": [
        "### Plot Dataset Samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sq9WQol_bk6r"
      },
      "outputs": [],
      "source": [
        "num_samples = 9\n",
        "\n",
        "num_rows = int(np.ceil(np.sqrt(num_samples)))\n",
        "num_cols = num_rows * 2\n",
        "\n",
        "samples_x = [train_x.next()[0] for _ in range(num_samples)]\n",
        "samples_y = [train_y.next()[0] for _ in range(num_samples)]\n",
        "\n",
        "fig = plt.figure(figsize=(20, 10))\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.9)\n",
        "fig.suptitle(f'{class_x.capitalize()} to {class_y.capitalize()}', fontsize=24)\n",
        "\n",
        "for i in range(num_rows):\n",
        "  for j in range(num_rows * 2):\n",
        "    sample = samples_x[i * num_rows + j] if j < num_rows else samples_y[(i - 1) * num_rows + j]\n",
        "    fig.add_subplot(num_rows, num_cols, i * num_cols + j + 1)\n",
        "    plt.title(class_x if j < num_rows else class_y)\n",
        "    plt.imshow(postprocess(sample))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrBwKr3GUXC2"
      },
      "source": [
        "# Create Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-e78acRcJgkz"
      },
      "source": [
        "### Define Model Building Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wF4ZiKrO32VG"
      },
      "outputs": [],
      "source": [
        "def create_generator():\n",
        "  init = tf.random_normal_initializer(0, 0.02)\n",
        "  base_filters = img_dim // 4\n",
        "  num_layers = int(np.log2(img_dim))\n",
        "  num_dropouts = max(1, num_layers - 5)\n",
        "  \n",
        "  skips = []\n",
        "\n",
        "  # input\n",
        "  generator_in = keras.Input(shape=img_shape)\n",
        "  x = generator_in\n",
        "\n",
        "  # downsample layers\n",
        "  for i in range(num_layers):\n",
        "    filters = min(base_filters * 2 ** i, 512)\n",
        "    x = downsample(x, filters, batch_norm=(i != 0))\n",
        "    skips.append(x)\n",
        "\n",
        "  # upsample layers\n",
        "  for i, skip in enumerate(reversed(skips[:-1])):\n",
        "    filters = min(base_filters * 2 ** (num_layers - i - 2), 512)\n",
        "    x = upsample(x, filters, dropout=(i < num_dropouts))\n",
        "    x = layers.Concatenate()((x, skip))\n",
        "  \n",
        "  # output layer\n",
        "  generator_out = layers.Conv2DTranspose(3, 4, 2, 'same', kernel_initializer=init, activation='tanh')(x)\n",
        "\n",
        "  # create generator\n",
        "  generator = keras.Model(inputs=generator_in, outputs=generator_out)\n",
        "\n",
        "  return generator\n",
        "\n",
        "\n",
        "def create_discriminator():\n",
        "  init = tf.random_normal_initializer(0, 0.02)\n",
        "  base_filters = img_dim // 4\n",
        "\n",
        "  # input\n",
        "  discriminator_in = keras.Input(shape=img_shape)\n",
        "  x = discriminator_in\n",
        "\n",
        "  # downsample layers\n",
        "  for i in range(3):\n",
        "    x = downsample(x, base_filters * (2 ** i), batch_norm=(i != 0))\n",
        "\n",
        "  # zero padding and final downsample layer\n",
        "  x = layers.ZeroPadding2D()(x)\n",
        "  x = downsample(x, base_filters * 8, strides=1, padding='valid')\n",
        "  x = layers.ZeroPadding2D()(x)\n",
        "  \n",
        "  # output layer\n",
        "  discriminator_out = layers.Conv2D(1, 4, 1, kernel_initializer=init)(x)\n",
        "\n",
        "  discriminator = keras.Model(inputs=discriminator_in, outputs=discriminator_out)\n",
        "\n",
        "  return discriminator\n",
        "\n",
        "\n",
        "def downsample(x, filters, strides=2, padding='same', batch_norm=True):\n",
        "  init = tf.random_normal_initializer(0, 0.02)\n",
        "  x = layers.Conv2D(filters, 4, strides, padding, kernel_initializer=init, use_bias=False)(x)\n",
        "  if batch_norm:\n",
        "    x = tfa_layers.InstanceNormalization()(x)\n",
        "  x = layers.LeakyReLU()(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def upsample(x, filters, dropout=False):\n",
        "  init = tf.random_normal_initializer(0, 0.02)\n",
        "  x = layers.Conv2DTranspose(filters, 4, 2, 'same', kernel_initializer=init, use_bias=False)(x)\n",
        "  x = tfa_layers.InstanceNormalization()(x)\n",
        "  if dropout:\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "  x = layers.ReLU()(x)\n",
        "  return x\n",
        "\n",
        "\n",
        "def plot_model(model, output_file): \n",
        "  return keras.utils.plot_model(model, to_file=output_file, show_shapes=True, show_layer_activations=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdIN4hlJJbu2"
      },
      "source": [
        "### Plot Generator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yl_vDkf4JbcN"
      },
      "outputs": [],
      "source": [
        "plot_model(create_generator(), f'{model_diagrams_dir}/generator_{img_dim}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFREEPtKJP6T"
      },
      "source": [
        "### Plot Discriminator Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EUXhAW46G6Vs"
      },
      "outputs": [],
      "source": [
        "plot_model(create_discriminator(), f'{model_diagrams_dir}/discriminator_{img_dim}.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvJV-69fUSeb"
      },
      "source": [
        "# Train CycleGAN\n",
        "$\\mathcal{L}_{G_{XY}} = BCE(\\textbf{1}, D_Y(G_{XY}(x))) + \\mathcal{L}_{cycle} + \\mathcal{L}_{id_{Y}}$\n",
        "\n",
        "$\\mathcal{L}_{G_{YX}} = BCE(\\textbf{1}, D_X(G_{YX}(y))) + \\mathcal{L}_{cycle} + \\mathcal{L}_{id_{X}}$\n",
        "\n",
        "$\\mathcal{L}_{D_X} = \\frac{1}{2} (BCE(\\textbf{1}, D_X(x)) + BCE(\\textbf{0}, D_X(G_{YX}(y))))$\n",
        "\n",
        "$\\mathcal{L}_{D_Y} = \\frac{1}{2} (BCE(\\textbf{1}, D_Y(y)) + BCE(\\textbf{0}, D_Y(G_{XY}(x))))$\n",
        "\n",
        "$\\mathcal{L}_{cycle} = \\lambda * (mean(|x - G_{YX}(G_{XY}(x))|)) + mean(|y - G_{XY}(G_{YX}(y))|))$\n",
        "\n",
        "$\\mathcal{L}_{id_{X}} = \\frac{\\lambda}{2} * mean(|x - G_{YX}(x)|)$\n",
        "\n",
        "$\\mathcal{L}_{id_{Y}} = \\frac{\\lambda}{2} * mean(|y - G_{XY}(y)|)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "di-q3CWCg41_"
      },
      "source": [
        "### Define Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BSWrx7yKO1TU"
      },
      "outputs": [],
      "source": [
        "def train(num_epochs, restore_epoch=0, checkpoint_freq=5):\n",
        "  np.save(f'{sample_images_dir}/{dataset_name}_x.npy', samples_x)\n",
        "  np.save(f'{sample_images_dir}/{dataset_name}_y.npy', samples_y)\n",
        "\n",
        "  avg_time_per_epoch = 0\n",
        "  for epoch in range(restore_epoch, num_epochs):\n",
        "    start = time.time()\n",
        "    iterations = min(len(train_x), len(train_y))\n",
        "    \n",
        "    # train cycle gan\n",
        "    for i in range(iterations):\n",
        "      print(f'\\rEpoch {epoch+1} Progress: {i+1}/{iterations}', end='')\n",
        "      real_x = train_x.next()\n",
        "      real_y = train_y.next()\n",
        "      train_step(real_x, real_y)\n",
        "\n",
        "    # save checkpoint\n",
        "    if (epoch + 1) % checkpoint_freq == 0:\n",
        "      checkpoint_manager.save()\n",
        "\n",
        "    # display training progress\n",
        "    generate_and_plot_images(f'Epoch {epoch+1}', plot_save_name=f'image_at_epoch_{(epoch+1):04d}')\n",
        "    avg_time_per_epoch = print_time_string(avg_time_per_epoch, start, epoch, num_epochs, restore_epoch)\n",
        "\n",
        "\n",
        "@tf.function\n",
        "def train_step(real_x, real_y):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    \n",
        "    # cycle real x\n",
        "    fake_y = generator_xy(real_x, training=True)\n",
        "    cycled_x = generator_yx(fake_y, training=True)\n",
        "\n",
        "    # cycle real y\n",
        "    fake_x = generator_yx(real_y, training=True)\n",
        "    cycled_y = generator_xy(fake_x, training=True)\n",
        "\n",
        "    # identities\n",
        "    same_x = generator_yx(real_x, training=True)\n",
        "    same_y = generator_xy(real_y, training=True)\n",
        "\n",
        "    # discriminator on real images\n",
        "    disc_real_x = discriminator_x(real_x, training=True)\n",
        "    disc_real_y = discriminator_y(real_y, training=True)\n",
        "    \n",
        "    # discriminator on fake images\n",
        "    disc_fake_x = discriminator_x(fake_x, training=True)\n",
        "    disc_fake_y = discriminator_y(fake_y, training=True)\n",
        "\n",
        "    # generator losses\n",
        "    generator_xy_loss = generator_loss(disc_fake_y)\n",
        "    generator_yx_loss = generator_loss(disc_fake_x)\n",
        "\n",
        "    # cycle loss\n",
        "    cycle_loss = cycle_consistency_loss(real_x, cycled_x) + cycle_consistency_loss(real_y, cycled_y)\n",
        "\n",
        "    # total generator losses\n",
        "    generator_xy_loss += cycle_loss + identity_loss(real_y, same_y)\n",
        "    generator_yx_loss += cycle_loss + identity_loss(real_x, same_x)\n",
        "\n",
        "    # total discriminator losses\n",
        "    discriminator_x_loss = discriminator_loss(disc_real_x, disc_fake_x)\n",
        "    discriminator_y_loss = discriminator_loss(disc_real_y, disc_fake_y)\n",
        "\n",
        "  generator_xy_gradients = tape.gradient(generator_xy_loss, generator_xy.trainable_variables)\n",
        "  generator_yx_gradients = tape.gradient(generator_yx_loss, generator_yx.trainable_variables)\n",
        "  discriminator_x_gradients = tape.gradient(discriminator_x_loss, discriminator_x.trainable_variables)\n",
        "  discriminator_y_gradients = tape.gradient(discriminator_y_loss, discriminator_y.trainable_variables)\n",
        "\n",
        "  generator_xy_optimizer.apply_gradients(zip(generator_xy_gradients, generator_xy.trainable_variables))\n",
        "  generator_yx_optimizer.apply_gradients(zip(generator_yx_gradients, generator_yx.trainable_variables))\n",
        "  discriminator_x_optimizer.apply_gradients(zip(discriminator_x_gradients, discriminator_x.trainable_variables))\n",
        "  discriminator_y_optimizer.apply_gradients(zip(discriminator_y_gradients, discriminator_y.trainable_variables))\n",
        "\n",
        "\n",
        "def discriminator_loss(real, fake):\n",
        "  real_loss = bce_loss(tf.ones_like(real), real)\n",
        "  fake_loss = bce_loss(tf.zeros_like(fake), fake)\n",
        "  return (real_loss + fake_loss) / 2\n",
        "\n",
        "\n",
        "def generator_loss(fake):\n",
        "  return bce_loss(tf.ones_like(fake), fake)\n",
        "\n",
        "\n",
        "def cycle_consistency_loss(real_image, cycled_image):\n",
        "  return λ * tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
        "\n",
        "\n",
        "def identity_loss(real_image, same_image):\n",
        "  return λ / 2 * tf.reduce_mean(tf.abs(real_image - same_image))\n",
        "\n",
        "\n",
        "def generate_and_plot_images(title, plot_save_name=None):\n",
        "  display.clear_output(wait=True)\n",
        "\n",
        "  fake_y = generator_xy(samples_x)\n",
        "  cycled_x = generator_yx(fake_y)\n",
        "\n",
        "  fake_x = generator_yx(samples_y)\n",
        "  cycled_y = generator_xy(fake_x)\n",
        "\n",
        "  fig = plt.figure(figsize=(20, 10))\n",
        "  fig.tight_layout()\n",
        "  fig.subplots_adjust(top=0.9)\n",
        "  fig.suptitle(title, fontsize=24)\n",
        "  \n",
        "  for i, images in enumerate(zip(samples_x, fake_y, cycled_x)):\n",
        "    titles = [class_x, f'{class_x} to {class_y}', f'{class_x} to {class_y} to {class_x}']\n",
        "    for j, (image, title) in enumerate(zip(images, titles)):\n",
        "      fig.add_subplot(3, 6, 6 * i + j + 1)\n",
        "      plt.title(title)\n",
        "      plt.imshow(postprocess(image))\n",
        "      plt.axis('off')\n",
        "\n",
        "  for i, images in enumerate(zip(samples_y, fake_x, cycled_y)):\n",
        "    titles = [class_y, f'{class_y} to {class_x}', f'{class_y} to {class_x} to {class_y}']\n",
        "    for j, (image, title) in enumerate(zip(images, titles)):\n",
        "      fig.add_subplot(3, 6, 6 * i + j + 4)\n",
        "      plt.title(title)\n",
        "      plt.imshow(postprocess(image))\n",
        "      plt.axis('off')\n",
        "  \n",
        "  if plot_save_name:\n",
        "    plt.savefig(f'{output_images_dir}/{plot_save_name}.png', bbox_inches='tight')\n",
        "  plt.show()\n",
        "  \n",
        "\n",
        "def print_time_string(avg_time_per_epoch, start, epoch, num_epochs, restore_epoch):\n",
        "  time_for_epoch = time.time() - start\n",
        "  epoch_adj = epoch - restore_epoch\n",
        "  avg_time_per_epoch = (avg_time_per_epoch * epoch_adj + time_for_epoch) / (epoch_adj + 1)\n",
        "  remaining_epochs = num_epochs - (epoch_adj + 1)\n",
        "  remaining_time = remaining_epochs * avg_time_per_epoch\n",
        "  print(f'Time For Epoch {epoch + 1}: {get_time_string(time_for_epoch)}')\n",
        "  print(f'Remaining Time: {get_time_string(remaining_time)}')\n",
        "  return avg_time_per_epoch\n",
        "\n",
        "\n",
        "def get_time_string(total_seconds):\n",
        "  hours = int(total_seconds // 3600)\n",
        "  remainder = total_seconds % 3600\n",
        "  minutes = int(remainder // 60)\n",
        "  seconds = round(remainder % 60, 2)\n",
        "  time_string = ''\n",
        "  if hours > 0:\n",
        "    time_string += f'{hours}h '\n",
        "  if remainder >= 60:\n",
        "    time_string += f'{minutes}m '\n",
        "  time_string += f'{seconds}s'\n",
        "  return time_string"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sd76SLaLyXCl"
      },
      "source": [
        "### Setup Models And Configure Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEoSQ7wifqiM"
      },
      "outputs": [],
      "source": [
        "λ = 10\n",
        "\n",
        "generator_xy = create_generator()\n",
        "generator_yx = create_generator()\n",
        "\n",
        "discriminator_x = create_discriminator()\n",
        "discriminator_y = create_discriminator()\n",
        "\n",
        "generator_xy_optimizer = optimizers.Adam(2e-4, beta_1=0.5)\n",
        "generator_yx_optimizer = optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_x_optimizer = optimizers.Adam(2e-4, beta_1=0.5)\n",
        "discriminator_y_optimizer = optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "bce_loss = losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "samples_x = np.array([train_x.next()[0] for _ in range(3)])\n",
        "samples_y = np.array([train_y.next()[0] for _ in range(3)])\n",
        "\n",
        "checkpoint = tf.train.Checkpoint(\n",
        "  generator_xy=generator_xy,\n",
        "  generator_yx=generator_yx,\n",
        "  discriminator_x=discriminator_x,\n",
        "  discriminator_y=discriminator_y,\n",
        "  generator_xy_optimizer=generator_xy_optimizer,\n",
        "  generator_yx_optimizer=generator_yx_optimizer,\n",
        "  discriminator_x_optimizer=discriminator_x_optimizer,\n",
        "  discriminator_y_optimizer=discriminator_y_optimizer,\n",
        ")\n",
        "checkpoint_manager = tf.train.CheckpointManager(checkpoint, checkpoint_dir, max_to_keep=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4c5_bD81neJQ"
      },
      "source": [
        "### Restore Latest Checkpoint\n",
        "(if necessary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8GwTOlom3OM"
      },
      "outputs": [],
      "source": [
        "if checkpoint_manager.latest_checkpoint:\n",
        "  checkpoint.restore(checkpoint_manager.latest_checkpoint)\n",
        "  samples_x = np.load(f'{sample_images_dir}/{dataset_name}_x.npy')\n",
        "  samples_y = np.load(f'{sample_images_dir}/{dataset_name}_y.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCd5ZLt_ybyg"
      },
      "source": [
        "### Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2WlRntRnKyT"
      },
      "outputs": [],
      "source": [
        "train(100, checkpoint_freq=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMbeQ2MBqOw2"
      },
      "source": [
        "### Save Generators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFBOsYjsRpfo"
      },
      "outputs": [],
      "source": [
        "models.save_model(generator_xy, f'{generators_dir}/{class_x}2{class_y}')\n",
        "models.save_model(generator_yx, f'{generators_dir}/{class_y}2{class_x}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dzi8gG5qxOq"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrHLvA-erWCF"
      },
      "source": [
        "### Load Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hBKIYtRrq8K7"
      },
      "outputs": [],
      "source": [
        "img_dim = 256\n",
        "img_shape = (img_dim, img_dim, 3)\n",
        "\n",
        "datagen = ImageDataGenerator(preprocessing_function=preprocess)\n",
        "\n",
        "x_test = datagen.flow_from_directory(\n",
        "  f'{dataset_name}/testX',\n",
        "  target_size=(img_dim, img_dim),\n",
        "  batch_size=1,\n",
        "  class_mode=None,\n",
        "  interpolation='box',\n",
        ")\n",
        "\n",
        "y_test = datagen.flow_from_directory(\n",
        "  f'{dataset_name}/testY',\n",
        "  target_size=(img_dim, img_dim),\n",
        "  batch_size=1,\n",
        "  class_mode=None,\n",
        "  interpolation='box',\n",
        ")\n",
        "\n",
        "samples_x = np.array([x_test.next()[0] for _ in range(3)])\n",
        "samples_y = np.array([y_test.next()[0] for _ in range(3)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3MAU4c-sNze"
      },
      "source": [
        "### Plot Images Generated From Test Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l7wT50Gtztz"
      },
      "outputs": [],
      "source": [
        "generate_and_plot_images('Test Set')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHjILqMsuMSC"
      },
      "source": [
        "### Test Images From The Web"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dxtnkR0aUJdY"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "response = requests.get('https://media.cntraveler.com/photos/60e612ae0a709e97d73d9c60/1:1/w_3840,h_3840,c_limit/Beach%20Vacation%20Packing%20List-2021_GettyImages-1030311160.jpg')\n",
        "img = Image.open(BytesIO(response.content))\n",
        "img = preprocess(np.expand_dims(np.array(img.resize((img_dim, img_dim))), 0))\n",
        "vg_img = postprocess(np.squeeze(generator_yx(img)))\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(vg_img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cycle_gan.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}